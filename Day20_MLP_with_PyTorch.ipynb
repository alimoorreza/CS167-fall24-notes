{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alimoorreza/CS167-fall24-notes/blob/main/Day20_MLP_with_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHJrUI0I4uVJ"
      },
      "source": [
        "# CS167: Day20\n",
        "\n",
        "## MLP using PyTorch\n",
        "\n",
        "### CS167: Machine Learning, Fall 2024\n",
        "\n",
        "\n",
        "ðŸ“† [Course Schedule](https://analytics.drake.edu/~reza/teaching/cs167_fall24/cs167_schedule.html) | ðŸ“œ [Syllabus](https://analytics.drake.edu/~reza/teaching/cs167_fall24/cs167_syllabus_fall24.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch library\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n"
      ],
      "metadata": {
        "id": "LwgBlHEvJDEJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating Linear Layers using PyTorch"
      ],
      "metadata": {
        "id": "8JllItQfeVFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build a linear layer**"
      ],
      "metadata": {
        "id": "K6snyzopmxi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2)                    # for reproducibility\n",
        "# construction of a linear layer\n",
        "num_of_neurons_input_layer      = 2\n",
        "num_of_neurons_output_layer     = 3\n",
        "\n",
        "input_linear_layer1              = nn.Linear(num_of_neurons_input_layer, num_of_neurons_output_layer)  # linear transformation module (input=2, output=3)\n",
        "input_linear_layer2              = nn.Linear(256, 4)  # linear transformation module (input=256, output=4)\n"
      ],
      "metadata": {
        "id": "WovTledem6Lw"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Inspecting the weights of a linear layer**"
      ],
      "metadata": {
        "id": "LbUkNgH5x0uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the weights of the linear layer\n",
        "print(f'Weights: \\n{input_linear_layer1.weight.data}')\n",
        "\n",
        "# Print the biases of the linear layer (if they exist)\n",
        "print(f'Biases: \\n{input_linear_layer1.bias.data}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_8I5F12xzuC",
        "outputId": "85aff31a-0958-414a-d3da-1ce3b85dc0af"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights: \n",
            "tensor([[ 0.1622, -0.1683],\n",
            "        [ 0.1939, -0.0361],\n",
            "        [ 0.3021,  0.1683]])\n",
            "Biases: \n",
            "tensor([-0.0813, -0.5717,  0.1614])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's generate a random input for our linear layer and plug it into our layer**"
      ],
      "metadata": {
        "id": "9-8gky6gn2rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 1 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 1\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = input_linear_layer1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2V0Gyc3oBzz",
        "outputId": "ecc05630-396c-4c09-bbf5-d2ca6317cba0",
        "collapsed": true
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 0.39229682 -0.22356401]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.01998059 -0.48752502  0.24230729]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate 3 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples     = 3\n",
        "random_input          = torch.randn(number_of_samples, 2)\n",
        "print(f'input numbers: \\n{random_input.numpy()}\\n')\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                = input_linear_layer1(random_input)\n",
        "print(f'output layer value: \\n{output.data.numpy()}\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB-XAtrPWuOi",
        "outputId": "8d310d2b-2e70-4062-f80d-6d3aa9c52054"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers: \n",
            "[[ 0.39229682 -0.22356401]\n",
            " [-0.31950027 -1.2050371 ]\n",
            " [ 1.0444635  -0.6332277 ]]\n",
            "\n",
            "output layer value: \n",
            "[[ 0.01998059 -0.48752502  0.24230729]\n",
            " [ 0.06968039 -0.5901005  -0.13792734]\n",
            " [ 0.19469965 -0.34626803  0.3703416 ]]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#1**\n",
        "Create a new Linear layer with the following structure:\n",
        "\n",
        "> The first layer has 3 input nodes and 6 output nodes.\n"
      ],
      "metadata": {
        "id": "a-LTmGiyp566"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "v_taKRZgqBde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#2**\n",
        "\n",
        "> Apply a tensor through your linear layer now.\n",
        "\n",
        "> Change the value in torch.manual_seed(0) to something else, generate new inputs, and pass the tensor through your linear layer again.\n",
        "\n",
        "> Observe the the output values."
      ],
      "metadata": {
        "id": "QVPRiA7ZqOfW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here.\n",
        "# ...\n",
        "\n"
      ],
      "metadata": {
        "id": "4hsvGpLUqbSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's add an activation function such as *ReLu(), tanh(), or sigmoid()* after your linear layer and run the experiment again to see how it changes the outputs.**"
      ],
      "metadata": {
        "id": "BOPOELyQsY1F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# construction of a linear layer\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "num_of_neurons_input_layer      = 2\n",
        "num_of_neurons_output_layer     = 3\n",
        "\n",
        "input_linear_layer              = nn.Linear(num_of_neurons_input_layer, num_of_neurons_output_layer)  # linear transformation module (input=2, output=3)\n",
        "sigmoid_activation              = nn.Sigmoid()\n",
        "tanh_activation                 = nn.Tanh()\n",
        "relu_activation                 = nn.ReLU()\n",
        "\n"
      ],
      "metadata": {
        "id": "DRw_QBK4sdTw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using Sigmoid activation function**"
      ],
      "metadata": {
        "id": "F0oBQ5evtzsO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples     = 1\n",
        "random_X              = torch.randn(number_of_samples, num_of_neurons_input_layer)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = sigmoid_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Sigmoid activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CW53vin-tVaH",
        "outputId": "cf2bc502-a0b8-4a44-965e-a32163708508",
        "collapsed": true
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.01998059 -0.48752502  0.24230729]]\n",
            "Sigmoid activation value: \n",
            "[[0.504995  0.3804768 0.5602822]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using Tanh activation function**"
      ],
      "metadata": {
        "id": "FJOLsCHuuOcB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples     = 1\n",
        "random_X              = torch.randn(number_of_samples, num_of_neurons_input_layer)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = tanh_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('Tanh() activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Imhy2qSIt6Jw",
        "outputId": "c1b0238e-6d7d-4abc-c7fb-df6f31988e4c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.01998059 -0.48752502  0.24230729]]\n",
            "Tanh() activation value: \n",
            "[[ 0.01997794 -0.45224985  0.2376739 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Using ReLU activation function**"
      ],
      "metadata": {
        "id": "3Ys-fzHCuqAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: let's generate some random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "number_of_samples     = 1\n",
        "random_X              = torch.randn(number_of_samples, num_of_neurons_input_layer)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# Step 2: apply forward pass through the network\n",
        "output                    = input_linear_layer(random_X)\n",
        "output_after_activation   = relu_activation(output)\n",
        "print('output layer value: ')\n",
        "print(output.data.numpy())\n",
        "print('ReLU() activation value: ')\n",
        "print(output_after_activation.data.numpy())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hg-a_ZfpuiWl",
        "outputId": "bcb30529-bea9-4688-db53-83ea1c335042"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "output layer value: \n",
            "[[ 0.01998059 -0.48752502  0.24230729]]\n",
            "ReLU() activation value: \n",
            "[[0.01998059 0.         0.24230729]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Group Exercise#3**\n",
        "\n",
        "> Experiment with different activation functions like sigmoid, tanh, and relu, and then pass a tensor through the linear layer you created for Group Exercises #1 and #2.\n",
        "\n",
        "> Change the value in torch.manual_seed(2) to something else, generate new inputs, and pass the tensor through your linear layer again.\n",
        "\n",
        "> Take a look at the output values and make sure they match what you were expecting!"
      ],
      "metadata": {
        "id": "OuOPEOQVu7XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here.\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "87sDNOLDv3yC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Let's build the simple 1-hidden layer feedforward neural network from the lecture slides!**\n",
        "\n",
        "<div>\n",
        "<img src=\"https://analytics.drake.edu/~reza/teaching/cs167_fall24/notes/images/mlp_toy_examle_wo_weights.png\" width=400/>\n",
        "</div>\n"
      ],
      "metadata": {
        "id": "0h5ShXNNliD1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make the simple 1-Hidden layer feedforwrd neural network from the lecture slides\n",
        "torch.manual_seed(2) # for reproducibility (you will get the same random number every time you run this cell)\n",
        "\n",
        "# construction\n",
        "num_of_neurons_input_layer      = 2\n",
        "num_of_neurons_1st_hidden_layer = 3\n",
        "num_of_neurons_output_layer     = 1\n",
        "\n",
        "'''\n",
        "# Alternatively, you could hardcode the values for the number of neurons directly, without using any variables such as 'num_of_neurons_input_layer ' or 'num_of_neurons_1st_hidden_layer'\n",
        "input_linear_layer              = nn.Linear(2, 3)\n",
        "output_linear_layer             = nn.Linear(3, 1) # linear transformation module (input=3, output=1)\n",
        "'''\n",
        "\n",
        "\n",
        "input_linear_layer              = nn.Linear(num_of_neurons_input_layer, num_of_neurons_1st_hidden_layer)  # linear transformation module (input=2, output=3)\n",
        "relu_activation_h1              = nn.ReLU()\n",
        "output_linear_layer             = nn.Linear(num_of_neurons_1st_hidden_layer, num_of_neurons_output_layer) # linear transformation module (input=3, output=1)\n",
        "\n"
      ],
      "metadata": {
        "id": "sml5o0uepNvZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **We can apply a tensor through the Linear layers now**"
      ],
      "metadata": {
        "id": "bN0-x03AlkfH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 2 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2)                                    # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples               = 1\n",
        "random_X = torch.randn(number_of_samples, 2)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# apply forward pass through the network\n",
        "output = input_linear_layer(random_X)\n",
        "output = relu_activation(output)\n",
        "print('1st-hidden layer feature map shape: ', output.shape)\n",
        "output = output_linear_layer(output)\n",
        "print('Output layer feature map shape: ', output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12dr7m-Mj1in",
        "outputId": "ce989240-172a-4a9d-ee60-d2ae608afe93",
        "collapsed": true
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "1st-hidden layer feature map shape:  torch.Size([1, 3])\n",
            "Output layer feature map shape:  torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **nn.Sequential()__ module:**\n",
        "You can use PyTorch's nn.Sequential module to build a network composed of multiple linear layers arranged sequentially."
      ],
      "metadata": {
        "id": "K260OHszjBAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_simple_network = nn.Sequential(\n",
        "    nn.Linear(2, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(3, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "WADDuQcPjL89"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's generate 2 random samples of (x1, x2) for the above linear network\n",
        "torch.manual_seed(2)                                    # for reproducibility (you will get the same random number every time you run this cell)\n",
        "number_of_samples               = 1\n",
        "random_X = torch.randn(number_of_samples, 2)             # you could imagine that these are pairs of (x1, x2) as shown in the above table\n",
        "print('input numbers:')\n",
        "print(random_X.numpy())\n",
        "\n",
        "\n",
        "# apply forward pass through the network\n",
        "output = my_simple_network(random_X)\n",
        "print('Output: ', output.data)\n",
        "print('Output layer feature map shape: ', output.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJX25JgJjbNJ",
        "outputId": "4d26a138-e3dc-48fe-a1f4-10535bff6f51"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input numbers:\n",
            "[[ 0.39229682 -0.22356401]]\n",
            "Output:  tensor([[0.2181]])\n",
            "Output layer feature map shape:  torch.Size([1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Group Exercise#4**\n",
        "Let's create three Linear layers and connect them in sequence to build an MLP with the following structure:\n",
        "\n",
        "> The first layer has 2 input nodes and 3 output nodes.\n",
        "\n",
        "> The second layer takes 3 input nodes and outputs 6 nodes.\n",
        "\n",
        "> The final layer connects 6 input nodes to 2 output nodes."
      ],
      "metadata": {
        "id": "Vn_XY5pRj_XE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "nxie_gB-mOqQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Group Exercise#5**\n",
        "> Apply a tensor through your MLP now."
      ],
      "metadata": {
        "id": "4ShpPaSFmSdf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# your code here\n",
        "# ...\n"
      ],
      "metadata": {
        "id": "d_RH5h0-j-wZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You could apply an input to individual layer as follows:"
      ],
      "metadata": {
        "id": "gicZ0vdZkATP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.randn(1, 2)\n",
        "print(f'input: {input.numpy()}')\n",
        "output = my_simple_network[0](input)\n",
        "print(f'{output.data}')\n",
        "print(f'shape: {output.shape}')\n",
        "\n",
        "# Try next layer\n",
        "\n",
        "\n",
        "\n",
        "# Try next next layer\n",
        "\n"
      ],
      "metadata": {
        "id": "ReH2hHydmnQY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}